---
hide:
  - toc
---

<div class="hero">
  <div class="hero__logo">
    <img src="assets/logo.png" alt="SuperClaw logo" />
  </div>
  <div class="hero__text">
    <h1>SuperClaw</h1>
    <p class="hero__tagline">Redâ€‘Team AI Agents Before They Redâ€‘Team You</p>
    <p class="hero__subtitle">Scenarioâ€‘driven, behaviorâ€‘first security testing for autonomous agents.</p>
    <div class="hero__cta">
      <a class="hero__button" href="getting-started/quickstart/">Get Started</a>
      <a class="hero__button hero__button--ghost" href="guides/attacks/">Run Your First Attack</a>
    </div>
  </div>
</div>

---

## âš ï¸ Security and Ethical Use (Read First)

SuperClaw is **for authorized security testing only**. You must:
- Obtain explicit permission before testing real systems
- Run tests in sandboxed or isolated environments
- Treat automated findings as signals, not proof

Guardrails:
- Local-only mode blocks remote targets by default
- Remote targets require `SUPERCLAW_AUTH_TOKEN` (or adapter token)

## What is SuperClaw?

SuperClaw is a comprehensive security testing framework for AI coding agents such as **OpenClaw** and agent ecosystems like **Moltbook**. It systematically identifies vulnerabilities through:

- **Prompt Injection** - Direct and indirect injection attacks
- **Tool Policy Bypass** - Alias confusion, group expansion exploits  
- **Sandbox Escape** - Container boundary testing
- **Multi-Agent Trust** - Inter-agent exploitation

## OpenClaw + Moltbook Threat Model

!!! warning "Threat Model"
    OpenClaw agents often run with broad tool access. When connected to **Moltbook** or other agent networks, they can ingest untrusted, adversarial content that enables:

    - Prompt injection and hidden instruction attacks  
    - Tool misuse and policy bypass  
    - Behavioral drift over time  
    - Cascading crossâ€‘agent exploitation  

    SuperClaw is built to evaluate these risks **before** deployment.

## Problem & Solution (Summary)

**Problem:** Agents are deployed with broad access, mutable behavior, and exposure to untrusted inputs, often without security validation. This leads to prompt injection, tool misuse, configuration drift, and data leakage discovered only after exposure.

**Solution:** SuperClaw performs **preâ€‘deployment, scenarioâ€‘driven security evaluation** of existing agents. It captures evidence (tool calls, outputs, artifacts), scores behavior against explicit contracts, and outputs actionable reports before agents touch sensitive data or external ecosystems.

**Nonâ€‘goals:** SuperClaw does **not** generate agents, run production workloads, or automate realâ€‘world exploitation.

## Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¯ **Attack Library** | 5 attack techniques with 100+ payloads |
| ğŸ” **Behavior Specs** | 6 security behaviors with severity levels |
| ğŸŒ¸ **Bloom Integration** | LLM-powered scenario generation |
| ğŸ“Š **Multi-Format Reports** | HTML, JSON, SARIF for CI/CD |
| ğŸ”¬ **CodeOptiX Integration** | Multi-modal evaluation pipeline |

## Quick Start

```bash
# Install
pip install superclaw

# Or with uv
uv pip install superclaw

# Run a security scan
superclaw attack openclaw --target ws://127.0.0.1:18789

# Generate report
superclaw audit openclaw --comprehensive --report-format html
```

## Part of Superagentic AI Ecosystem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Superagentic AI Ecosystem                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SuperQode    â”‚  TUI interface for SuperQE, CI/automation  â”‚
â”‚  SuperQE      â”‚  Quality Engineering core engine            â”‚
â”‚  SuperClaw    â”‚  Agent security testing framework â—„â”€â”€ YOU   â”‚
â”‚  CodeOptiX    â”‚  Code optimization & evaluation engine      â”‚
â”‚  Bloom        â”‚  Behavioral evaluation scenario generation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation Options

=== "pip"

    ```bash
    pip install superclaw
    ```

=== "uv"

    ```bash
    uv pip install superclaw
    ```

=== "With CodeOptiX"

    ```bash
    pip install superclaw[codeoptix]
    ```

=== "From SuperQode"

    ```bash
    pip install superqode[security]
    ```

## Next Steps

- [Installation Guide](getting-started/installation.md)
- [Quick Start Tutorial](getting-started/quickstart.md)
- [Architecture Overview](architecture/overview.md)

<div class="cards">
  <div class="card">
    <h3>Scenarioâ€‘Driven Testing</h3>
    <p>Generate adversarial scenarios and replay them against real agents.</p>
    <a href="getting-started/quickstart/">Learn more â†’</a>
  </div>
  <div class="card">
    <h3>Behavior Contracts</h3>
    <p>Explicit success criteria, evidence extraction, and mitigation guidance.</p>
    <a href="architecture/behaviors/">Explore behaviors â†’</a>
  </div>
  <div class="card">
    <h3>Evidenceâ€‘First Reporting</h3>
    <p>Reports include tool calls, outputs, and actionable fixes.</p>
    <a href="guides/attacks/">See reports â†’</a>
  </div>
  <div class="card">
    <h3>Guardrails</h3>
    <p>Localâ€‘only mode and authorization checks to reduce misuse.</p>
    <a href="guides/safety/">Safety guide â†’</a>
  </div>
</div>
